{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)\n",
      "matplotlib 3.3.2\n",
      "numpy 1.19.5\n",
      "pandas 1.1.3\n",
      "sklearn 0.24.0\n",
      "tensorflow 2.4.1\n",
      "tensorflow.keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl # python 绘图库\n",
    "import matplotlib.pyplot as plt # python 2D 绘图库\n",
    "import numpy as np # 数学库，矩阵数组等\n",
    "import sklearn\n",
    "import pandas as pd # 大数据处理模块\n",
    "import os # 处理文件和目录\n",
    "import sys # 解释器使用或维护一些变量的访问，以及与解释器强交互的函数\n",
    "import time # 格式化日期与时间\n",
    "import tensorflow as tf\n",
    " \n",
    "from tensorflow import keras\n",
    " \n",
    "#显示重要库的对应版本\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "# 引入加州房价预测数据\n",
    "housing = fetch_california_housing()\n",
    "# 显示数据的说明，数据的矩阵形状，标签的形状\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "# 引入机器学习数据集分割库\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 引入预测房价的 data，target，并切分数据为 训练集（训练集中又该分为训练集和验证集） 与 测试集，\n",
    "# x 为训练集,y 为测试集，这里将数据切割为 4 个部分，训练集的特征，验证集的特征，训练集的标签，验证集的标签\n",
    "# 没有填写训练集与验证的分割比例的话，默认为 0.75\n",
    "\n",
    "x_train_all,x_test,y_train_all,y_test = train_test_split(\n",
    "    housing.data,housing.target,random_state=7)\n",
    " \n",
    "# 将大训练集分割为小训练集与验证集\n",
    "x_train,x_valid,y_train,y_valid =train_test_split(\n",
    "    x_train_all,y_train_all,random_state=11)\n",
    " \n",
    "# 显示训练集，验证集，测试集的形状\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.226, 1.514, 1.598, ..., 1.5  , 2.636, 1.925])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入标准化库 ：计算训练集的平均值和标准差，以便测试数据集使用相同的变换\n",
    "from sklearn import preprocessing\n",
    " \n",
    "# 引入标准化函数\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# 训练集，验证集，测试集标准化\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.96598484,  0.19206119, -1.04889736, ...,  0.01281729,\n",
       "        -0.73906413,  0.63164745],\n",
       "       [ 0.24771283,  0.11196095, -0.15638057, ..., -0.0636657 ,\n",
       "        -0.85570637,  0.63164745],\n",
       "       [-0.08829461,  1.87416616, -0.23201227, ..., -0.1387746 ,\n",
       "         1.0105695 , -1.33078543],\n",
       "       ...,\n",
       "       [-0.39025373,  0.91296332, -0.26692829, ..., -0.01752361,\n",
       "        -0.74839551,  0.72152988],\n",
       "       [-0.93950281,  1.23336426, -0.96485108, ...,  0.18553096,\n",
       "         0.58599173, -1.09109897],\n",
       "       [ 0.94551706,  0.75276284,  0.23183458, ..., -0.04272383,\n",
       "        -0.71106999,  0.74150375]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现多输入 这里使用函数式的方法\n",
    "# 我们假设我们将前 5 个 feature 输入 wide 模型，后 6 个 feature 输入 deep 模型，一共 8 个 feature ，也就是说， wide and deep 有交集部分\n",
    "input_wide = keras.layers.Input(shape=[5])\n",
    "input_deep = keras.layers.Input(shape=[6])\n",
    "# deep model 有两个隐藏层\n",
    "hidden1 = keras.layers.Dense(30,activation='relu')(input_deep)\n",
    "hidden2 = keras.layers.Dense(15,activation='relu')(hidden1)\n",
    "# 合并两个模型的输出\n",
    "concat = keras.layers.concatenate([input_wide,hidden2])\n",
    "output =keras.layers.Dense(1)(concat)\n",
    "# 模型的输入为两个模型的输入，输出只有一个\n",
    "model = keras.models.Model(inputs = [input_wide,input_deep],\n",
    "                            outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           210         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 15)           465         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 20)           0           input_6[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            21          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 696\n",
      "Trainable params: 696\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer=\"Ftrl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(\n",
    "                patience= 5,min_delta=1e-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide 模型的输入，前 5 个特征的数据集 ,deep 模型输入后 6 个\n",
    "x_train_scaled_wide = x_train_scaled[:,:5]\n",
    "x_train_scaled_deep = x_train_scaled[:,2:]\n",
    "# 验证集和测试集同上\n",
    "x_valid_scaled_wide = x_valid_scaled[:,:5]\n",
    "x_valid_scaled_deep = x_valid_scaled[:,2:]\n",
    "x_test_scaled_wide = x_test_scaled[:,:5]\n",
    "x_test_scaled_deep = x_test_scaled[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "363/363 [==============================] - 5s 7ms/step - loss: 5.9362 - val_loss: 5.8513\n",
      "Epoch 2/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 5.3600 - val_loss: 5.2879\n",
      "Epoch 3/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 4.8810 - val_loss: 4.6622\n",
      "Epoch 4/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 4.2539 - val_loss: 4.0506\n",
      "Epoch 5/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 3.6729 - val_loss: 3.5066\n",
      "Epoch 6/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 3.1336 - val_loss: 3.0540\n",
      "Epoch 7/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 2.7738 - val_loss: 2.6968\n",
      "Epoch 8/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 2.4800 - val_loss: 2.4255\n",
      "Epoch 9/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 2.2515 - val_loss: 2.2250\n",
      "Epoch 10/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 2.0060 - val_loss: 2.0781\n",
      "Epoch 11/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.8359 - val_loss: 1.9710\n",
      "Epoch 12/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.7691 - val_loss: 1.8908\n",
      "Epoch 13/200\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 1.7653 - val_loss: 1.8291\n",
      "Epoch 14/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.7005 - val_loss: 1.7797\n",
      "Epoch 15/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.6258 - val_loss: 1.7381\n",
      "Epoch 16/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.5796 - val_loss: 1.7019\n",
      "Epoch 17/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.5872 - val_loss: 1.6694\n",
      "Epoch 18/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.5817 - val_loss: 1.6392\n",
      "Epoch 19/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.4812 - val_loss: 1.6116\n",
      "Epoch 20/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.4971 - val_loss: 1.5857\n",
      "Epoch 21/200\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 1.4693 - val_loss: 1.5614\n",
      "Epoch 22/200\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.4362 - val_loss: 1.5384\n",
      "Epoch 23/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.4096 - val_loss: 1.5165\n",
      "Epoch 24/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.4524 - val_loss: 1.4956\n",
      "Epoch 25/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.3958 - val_loss: 1.4756\n",
      "Epoch 26/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.3456 - val_loss: 1.4563\n",
      "Epoch 27/200\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 1.3384 - val_loss: 1.4378\n",
      "Epoch 28/200\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 1.3470 - val_loss: 1.4200\n",
      "Epoch 29/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.3075 - val_loss: 1.4028\n",
      "Epoch 30/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.2942 - val_loss: 1.3862\n",
      "Epoch 31/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.2460 - val_loss: 1.3701\n",
      "Epoch 32/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.3083 - val_loss: 1.3545\n",
      "Epoch 33/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.2673 - val_loss: 1.3393\n",
      "Epoch 34/200\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 1.2488 - val_loss: 1.3246\n",
      "Epoch 35/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.2727 - val_loss: 1.3104\n",
      "Epoch 36/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.2071 - val_loss: 1.2965\n",
      "Epoch 37/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.2142 - val_loss: 1.2829\n",
      "Epoch 38/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.1949 - val_loss: 1.2698\n",
      "Epoch 39/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.1938 - val_loss: 1.2570\n",
      "Epoch 40/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.1474 - val_loss: 1.2446\n",
      "Epoch 41/200\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.1819 - val_loss: 1.2325\n",
      "Epoch 42/200\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.1261 - val_loss: 1.2206\n",
      "Epoch 43/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.1097 - val_loss: 1.2091\n",
      "Epoch 44/200\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 1.1292 - val_loss: 1.1979\n",
      "Epoch 45/200\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 1.1158 - val_loss: 1.1869\n",
      "Epoch 46/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.0998 - val_loss: 1.1762\n",
      "Epoch 47/200\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.1154 - val_loss: 1.1658\n",
      "Epoch 48/200\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 1.1026 - val_loss: 1.1557\n",
      "Epoch 49/200\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.0654 - val_loss: 1.1459\n",
      "Epoch 50/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.1001 - val_loss: 1.1363\n",
      "Epoch 51/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0710 - val_loss: 1.1269\n",
      "Epoch 52/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0760 - val_loss: 1.1178\n",
      "Epoch 53/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0625 - val_loss: 1.1089\n",
      "Epoch 54/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.0430 - val_loss: 1.1002\n",
      "Epoch 55/200\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.0410 - val_loss: 1.0917\n",
      "Epoch 56/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0391 - val_loss: 1.0835\n",
      "Epoch 57/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0119 - val_loss: 1.0754\n",
      "Epoch 58/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0180 - val_loss: 1.0676\n",
      "Epoch 59/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0009 - val_loss: 1.0599\n",
      "Epoch 60/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.0005 - val_loss: 1.0524\n",
      "Epoch 61/200\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.9618 - val_loss: 1.0450\n",
      "Epoch 62/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0107 - val_loss: 1.0379\n",
      "Epoch 63/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.9559 - val_loss: 1.0310\n",
      "Epoch 64/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.9722 - val_loss: 1.0241\n",
      "Epoch 65/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.9550 - val_loss: 1.0175\n",
      "Epoch 66/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.9551 - val_loss: 1.0111\n",
      "Epoch 67/200\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.9560 - val_loss: 1.0048\n",
      "Epoch 68/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.9427 - val_loss: 0.9986\n",
      "Epoch 69/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.9479 - val_loss: 0.9926\n",
      "Epoch 70/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.9615 - val_loss: 0.9867\n",
      "Epoch 71/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.9195 - val_loss: 0.9810\n",
      "Epoch 72/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8881 - val_loss: 0.9753\n",
      "Epoch 73/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.9100 - val_loss: 0.9698\n",
      "Epoch 74/200\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.9136 - val_loss: 0.9645\n",
      "Epoch 75/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.9086 - val_loss: 0.9592\n",
      "Epoch 76/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8741 - val_loss: 0.9541\n",
      "Epoch 77/200\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.9066 - val_loss: 0.9491\n",
      "Epoch 78/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8769 - val_loss: 0.9442\n",
      "Epoch 79/200\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.8617 - val_loss: 0.9393\n",
      "Epoch 80/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.8561 - val_loss: 0.9347\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 3s 7ms/step - loss: 0.8638 - val_loss: 0.9300\n",
      "Epoch 82/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8702 - val_loss: 0.9255\n",
      "Epoch 83/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8633 - val_loss: 0.9211\n",
      "Epoch 84/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8743 - val_loss: 0.9168\n",
      "Epoch 85/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8631 - val_loss: 0.9126\n",
      "Epoch 86/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8664 - val_loss: 0.9084\n",
      "Epoch 87/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8489 - val_loss: 0.9044\n",
      "Epoch 88/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8362 - val_loss: 0.9004\n",
      "Epoch 89/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8622 - val_loss: 0.8965\n",
      "Epoch 90/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8603 - val_loss: 0.8927\n",
      "Epoch 91/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8375 - val_loss: 0.8890\n",
      "Epoch 92/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8418 - val_loss: 0.8854\n",
      "Epoch 93/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8206 - val_loss: 0.8818\n",
      "Epoch 94/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8158 - val_loss: 0.8783\n",
      "Epoch 95/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8204 - val_loss: 0.8748\n",
      "Epoch 96/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8451 - val_loss: 0.8715\n",
      "Epoch 97/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8218 - val_loss: 0.8682\n",
      "Epoch 98/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8079 - val_loss: 0.8649\n",
      "Epoch 99/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8029 - val_loss: 0.8617\n",
      "Epoch 100/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7994 - val_loss: 0.8586\n",
      "Epoch 101/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8260 - val_loss: 0.8556\n",
      "Epoch 102/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8167 - val_loss: 0.8526\n",
      "Epoch 103/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8168 - val_loss: 0.8497\n",
      "Epoch 104/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8148 - val_loss: 0.8468\n",
      "Epoch 105/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.8057 - val_loss: 0.8439\n",
      "Epoch 106/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8029 - val_loss: 0.8412\n",
      "Epoch 107/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8108 - val_loss: 0.8384\n",
      "Epoch 108/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7861 - val_loss: 0.8358\n",
      "Epoch 109/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7807 - val_loss: 0.8331\n",
      "Epoch 110/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7968 - val_loss: 0.8305\n",
      "Epoch 111/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7934 - val_loss: 0.8280\n",
      "Epoch 112/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.7886 - val_loss: 0.8255\n",
      "Epoch 113/200\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.7930 - val_loss: 0.8230\n",
      "Epoch 114/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7675 - val_loss: 0.8206\n",
      "Epoch 115/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7658 - val_loss: 0.8182\n",
      "Epoch 116/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7688 - val_loss: 0.8159\n",
      "Epoch 117/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7650 - val_loss: 0.8135\n",
      "Epoch 118/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7872 - val_loss: 0.8113\n",
      "Epoch 119/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7546 - val_loss: 0.8091\n",
      "Epoch 120/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.7880 - val_loss: 0.8069\n",
      "Epoch 121/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.7445 - val_loss: 0.8047\n",
      "Epoch 122/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7645 - val_loss: 0.8026\n",
      "Epoch 123/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.7561 - val_loss: 0.8006\n",
      "Epoch 124/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7566 - val_loss: 0.7985\n",
      "Epoch 125/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7534 - val_loss: 0.7965\n",
      "Epoch 126/200\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7693 - val_loss: 0.7945\n",
      "Epoch 127/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.7532 - val_loss: 0.7925\n",
      "Epoch 128/200\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.7524 - val_loss: 0.7906\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train_scaled_wide,x_train_scaled_deep],\n",
    "                    y_train,\n",
    "                    validation_data=(\n",
    "                                    [x_valid_scaled_wide,x_valid_scaled_deep],\n",
    "                                    y_valid),\n",
    "                    epochs = 200,\n",
    "                    callbacks = callbacks\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x57b20d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 设定图表展示函数，将模型训练的接受对象 history 输入到该函数中\n",
    "def plot_learning_curves(history):\n",
    "# 将 history 获取到的训练过程的参数变化的字典变为矩阵形状，并设定图的尺寸大小为 8 和 5\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "# 显示网格\n",
    "    plt.grid(True)\n",
    "# 设置坐标范围 ，设定 y 为 0~1 之间\n",
    "    plt.gca().set_ylim(0,1)\n",
    "# 显示这张图\n",
    "    plt.show()\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 711us/step - loss: 0.7535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7535200715065002"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入测试集的特征与标签\n",
    "model.evaluate([x_test_scaled_wide, x_test_scaled_deep],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
