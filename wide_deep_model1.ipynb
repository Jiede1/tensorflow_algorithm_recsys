{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 定义输入样本格式\n",
    "_CSV_COLUMNS = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "    'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "    'income_bracket'\n",
    "]\n",
    "_CSV_COLUMN_DEFAULTS = [[0], [''], [0], [''], [0], [''], [''], [''], [''], [''],\n",
    "                        [0], [0], [0], [''], ['']]\n",
    "_NUM_EXAMPLES = {\n",
    "    'train': 32561,\n",
    "    'validation': 16281,\n",
    "}\n",
    "\n",
    "\"\"\"Builds a set of wide and deep feature columns.\"\"\"\n",
    "\n",
    "\n",
    "def build_model_columns():\n",
    "    # 1. 特征处理，包括：连续特征、离散特征、转换特征、交叉特征等\n",
    "\n",
    "    # 连续特征 （其中在Wide和Deep组件都会用到）\n",
    "    age = tf.feature_column.numeric_column('age')\n",
    "    education_num = tf.feature_column.numeric_column('education_num')\n",
    "    capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "    capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "    hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n",
    "\n",
    "    # 离散特征\n",
    "    education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'education', [\n",
    "            'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\n",
    "            'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\n",
    "            '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])\n",
    "\n",
    "    marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'marital_status', [\n",
    "            'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',\n",
    "            'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])\n",
    "\n",
    "    relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'relationship', [\n",
    "            'Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried',\n",
    "            'Other-relative'])\n",
    "\n",
    "    workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'workclass', [\n",
    "            'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',\n",
    "            'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])\n",
    "\n",
    "    # 离散hash bucket特征\n",
    "    occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'occupation', hash_bucket_size=1000\n",
    "    )\n",
    "\n",
    "    # 特征Transformations\n",
    "    age_buckets = tf.feature_column.bucketized_column(\n",
    "        age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65]\n",
    "    )\n",
    "\n",
    "    # 2. 设定Wide层特征\n",
    "    \"\"\"\n",
    "    Wide部分使用了规范化后的连续特征、离散特征、交叉特征\n",
    "    \"\"\"\n",
    "    # 基本特征列\n",
    "    base_columns = [\n",
    "        # 全是离散特征\n",
    "        education, marital_status, relationship, workclass, occupation,\n",
    "        age_buckets,\n",
    "    ]\n",
    "\n",
    "    # 交叉特征列\n",
    "    crossed_columns = [\n",
    "        tf.feature_column.crossed_column(\n",
    "            ['education', 'occupation'], hash_bucket_size=1000),\n",
    "        tf.feature_column.crossed_column(\n",
    "            [age_buckets, 'education', 'occupation'], hash_bucket_size=1000\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # wide特征列\n",
    "    wide_columns = base_columns + crossed_columns\n",
    "\n",
    "    # 3. 设定Deep层特征\n",
    "    \"\"\"\n",
    "    Deep层主要针对离散特征进行处理，其中处理方式有：\n",
    "    1. Sparse Features -> Embedding vector -> 串联(连续特征)，其中Embedding Values随机初始化。\n",
    "    2. 另外一种处理离散特征的方法是：one-hot和multi-hot representation. 此方法适用于低维度特征，其中embedding是通用的做法\n",
    "    其中：采用embedding_column(embedding)和indicator_column(multi-hot)API\n",
    "    \"\"\"\n",
    "    # deep特征列\n",
    "    deep_columns = [\n",
    "        age,\n",
    "        education_num,\n",
    "        capital_gain,\n",
    "        capital_loss,\n",
    "        hours_per_week,\n",
    "        tf.feature_column.indicator_column(workclass),\n",
    "        tf.feature_column.indicator_column(education),\n",
    "        tf.feature_column.indicator_column(marital_status),\n",
    "        tf.feature_column.indicator_column(relationship),\n",
    "\n",
    "        # embedding特征\n",
    "        tf.feature_column.embedding_column(occupation, dimension=8)\n",
    "    ]\n",
    "\n",
    "    return wide_columns, deep_columns\n",
    "\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "    \"\"\"为Estimator创建一个input function\"\"\"\n",
    "\n",
    "    def parse_csv(line):\n",
    "        print(\"Parsing\", data_file)\n",
    "        # tf.decode_csv会把csv文件转换成Tensor。其中record_defaults用于指明每一列的缺失值用什么填充。\n",
    "        columns = tf.io.decode_csv(line, record_defaults=_CSV_COLUMN_DEFAULTS)\n",
    "        features = dict(zip(_CSV_COLUMNS, columns))\n",
    "        # pop函数提取label\n",
    "        labels = features.pop('income_bracket')\n",
    "        # tf.equal(x, y) 返回一个bool类型Tensor， 表示x == y, element-wise\n",
    "        return features, tf.equal(labels, '>50K')\n",
    "\n",
    "    dataset = tf.data.TextLineDataset(data_file).map(parse_csv, num_parallel_calls=5)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels\n",
    "\n",
    "\n",
    "# Wide & Deep Model\n",
    "def build_estimator(model_dir, model_type):\n",
    "    \"\"\"Build an estimator appropriate for the given model type.\"\"\"\n",
    "    wide_columns, deep_columns = build_model_columns()\n",
    "    hidden_units = [100, 50]\n",
    "    if model_type == 'wide':\n",
    "        return tf.estimator.LinearClassifier(\n",
    "            model_dir=model_dir,\n",
    "            feature_columns=wide_columns)\n",
    "    elif model_type == 'deep':\n",
    "        return tf.estimator.DNNClassifier(\n",
    "            model_dir=model_dir,\n",
    "            feature_columns=deep_columns,\n",
    "            hidden_units=hidden_units)\n",
    "    else:\n",
    "        return tf.estimator.DNNLinearCombinedClassifier(\n",
    "            model_dir=model_dir,\n",
    "            linear_feature_columns=wide_columns,\n",
    "            dnn_feature_columns=deep_columns,\n",
    "            dnn_hidden_units=hidden_units)\n",
    "\n",
    "\n",
    "# 模型路径\n",
    "model_type = 'widedeep'\n",
    "model_dir = '/Users/ivan.ge/Documents/recommendation system/DeepRecommendationModel/代码'\n",
    "\n",
    "# Wide & Deep 联合模型\n",
    "model = build_estimator(model_dir, model_type)\n",
    "\n",
    "# ## 4）模型训练\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "# 训练参数\n",
    "train_epochs = 10\n",
    "batch_size = 5000\n",
    "train_file = '/Users/ivan.ge/Documents/recommendation system/DeepRecommendationModel/代码/data/adult.data'\n",
    "test_file = '/Users/ivan.ge/Documents/recommendation system/DeepRecommendationModel/代码/data/adult.test'\n",
    "\n",
    "# 6. 开始训练\n",
    "for n in range(train_epochs):\n",
    "    # 模型训练\n",
    "    model.train(input_fn=lambda: input_fn(train_file, train_epochs, True, batch_size))\n",
    "    # 模型评估\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(test_file, 1, False, batch_size))\n",
    "    # 打印评估结果\n",
    "    print(\"Results at epoch {0}\".format((n + 1) * train_epochs))\n",
    "    print('-' * 30)\n",
    "    for key in sorted(results):\n",
    "        print(\"{0:20}: {1:.4f}\".format(key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "X_scaled = preprocessing.scale(X_train)\n",
    "\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "scaler\n",
    "\n",
    "\n",
    "scaler.mean_                                      \n",
    "\n",
    "\n",
    "scaler.scale_                                       \n",
    "\n",
    "\n",
    "scaler.transform(X_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
